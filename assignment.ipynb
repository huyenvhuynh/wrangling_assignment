{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ad028b-72b7-43ed-aa78-96fd4e518040",
   "metadata": {
    "id": "13ad028b-72b7-43ed-aa78-96fd4e518040"
   },
   "source": [
    "# Assignment: Data Wrangling\n",
    "### `! git clone https://github.com/ds3001f25/wrangling_assignment.git`\n",
    "### Do Q1 and Q2\n",
    "### Reading material: `tidy_data.pdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "993e47be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\huyen\\appdata\\roaming\\python\\python310\\site-packages (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\huyen\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\huyen\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\huyen\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\huyen\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\huyen\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fastparquet\n",
      "  Downloading fastparquet-2024.11.0-cp310-cp310-win_amd64.whl (670 kB)\n",
      "     -------------------------------------- 670.7/670.7 kB 6.1 MB/s eta 0:00:00\n",
      "Collecting cramjam>=2.3\n",
      "  Downloading cramjam-2.11.0-cp310-cp310-win_amd64.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 18.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\huyen\\appdata\\roaming\\python\\python310\\site-packages (from fastparquet) (25.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\huyen\\appdata\\roaming\\python\\python310\\site-packages (from fastparquet) (2.2.6)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "     ------------------------------------- 199.6/199.6 kB 12.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\huyen\\appdata\\roaming\\python\\python310\\site-packages (from fastparquet) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\huyen\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\huyen\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\huyen\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=1.5.0->fastparquet) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\huyen\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "Installing collected packages: fsspec, cramjam, fastparquet\n",
      "Successfully installed cramjam-2.11.0 fastparquet-2024.11.0 fsspec-2025.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install fastparquet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072",
   "metadata": {
    "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072"
   },
   "source": [
    "**Q1.** This question provides some practice cleaning variables which have common problems.\n",
    "1. Numeric variable: For `./data/airbnb_hw.csv`, clean the `Price` variable as well as you can, and explain the choices you make. How many missing values do you end up with? (Hint: What happens to the formatting when a price goes over 999 dollars, say from 675 to 1,112?)\n",
    "2. Categorical variable: For the Minnesota police use of for data, `./data/mn_police_use_of_force.csv`, clean the `subject_injury` variable, handling the NA's; this gives a value `Yes` when a person was injured by police, and `No` when no injury occurred. What proportion of the values are missing? Is this a concern? Cross-tabulate your cleaned `subject_injury` variable with the `force_type` variable. Are there any patterns regarding when the data are missing? \n",
    "3. Dummy variable: For the pretrial data covered in the lecture `./data/justice_data.parquet`, clean the `WhetherDefendantWasReleasedPretrial` variable as well as you can, and, in particular, replace missing values with `np.nan`.\n",
    "4. Missing values, not at random: For the pretrial data covered in the lecture, clean the `ImposedSentenceAllChargeInContactEvent` variable as well as you can, and explain the choices you make. (Hint: Look at the `SentenceTypeAllChargesAtConvictionInContactEvent` variable.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d33ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "# Number 1\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./data/airbnb_hw.csv\")\n",
    "\n",
    "df['Price'].head(10)\n",
    "\n",
    "df['Price_clean'] = (\n",
    "    df['Price']\n",
    "    .astype(str)                      # ensure string\n",
    "    .str.replace(\"$\", \"\", regex=False)  # remove $\n",
    "    .str.replace(\",\", \"\", regex=False)  # remove commas\n",
    "    .str.strip()                        # remove spaces\n",
    ")\n",
    "\n",
    "df['Price_clean'] = pd.to_numeric(df['Price_clean'], errors='coerce')\n",
    "\n",
    "print(f\"Missing values after cleaning: {df['Price_clean'].isna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "459fcc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion missing: 76.19%\n",
      "force_type            Baton  Bodily Force  Chemical Irritant  Firearm  \\\n",
      "subject_injury_clean                                                    \n",
      "Nan                       2          7051               1421        0   \n",
      "No                        0          1093                131        2   \n",
      "Yes                       2          1286                 41        0   \n",
      "\n",
      "force_type            Gun Point Display  Improvised Weapon  Less Lethal  \\\n",
      "subject_injury_clean                                                      \n",
      "Nan                                  27                 74           87   \n",
      "No                                   33                 34            0   \n",
      "Yes                                  44                 40            0   \n",
      "\n",
      "force_type            Less Lethal Projectile  Maximal Restraint Technique  \\\n",
      "subject_injury_clean                                                        \n",
      "Nan                                        0                          170   \n",
      "No                                         1                            0   \n",
      "Yes                                        2                            0   \n",
      "\n",
      "force_type            Police K9 Bite  Taser  \n",
      "subject_injury_clean                         \n",
      "Nan                               31    985  \n",
      "No                                 2    150  \n",
      "Yes                               44    172  \n"
     ]
    }
   ],
   "source": [
    "# Number 2\n",
    "\n",
    "df2 = pd.read_csv(\"./data/mn_police_use_of_force.csv\")\n",
    "\n",
    "df2['subject_injury_clean'] = (\n",
    "    df2['subject_injury']\n",
    "    .str.strip()\n",
    "    .str.capitalize()\n",
    "    .replace(\n",
    "        {'Nan': pd.NA, '': pd.NA}\n",
    "    )\n",
    ")\n",
    "\n",
    "missing_count_mean = df2['subject_injury_clean'].isna().mean()\n",
    "print(f\"Proportion missing: {missing_count_mean:.2%}\")\n",
    "\n",
    "# Cross-tabulate with force_type\n",
    "ct = pd.crosstab(df['subject_injury_clean'], df['force_type'], dropna=False)\n",
    "print(ct)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad3a3da",
   "metadata": {},
   "source": [
    "Number 2\n",
    "\n",
    "76.19% of the values are missing. Yes that is a concern. For patterns, bodily force seems to be the highest category of data missing. Chemical irritant and taser seem to be a close second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf838e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number 3\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "justice = pd.read_parquet(\"./data/justice_data.parquet\", engine=\"fastparquet\")\n",
    "\n",
    "justice['released_clean'] = (\n",
    "    justice['WhetherDefendantWasReleasedPretrial']\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    ")\n",
    "\n",
    "# Map to Yes/No\n",
    "justice['released_clean'] = justice['released_clean'].replace({\n",
    "    'yes': 'Yes',\n",
    "    'y': 'Yes',\n",
    "    'released': 'Yes',\n",
    "    'no': 'No',\n",
    "    'n': 'No',\n",
    "    'not released': 'No',\n",
    "    'nan': np.nan,\n",
    "    '': np.nan,\n",
    "})\n",
    "\n",
    "justice['released_dummy'] = justice['released_clean'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530627f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: 9053 (39.38%)\n"
     ]
    }
   ],
   "source": [
    "# Number 4\n",
    "\n",
    "justice['ImposedSentenceAllChargeInContactEvent'].value_counts(dropna=False)\n",
    "justice['SentenceTypeAllChargesAtConvictionInContactEvent'].value_counts(dropna=False)\n",
    "\n",
    "justice['imposed_sentence_clean'] = pd.to_numeric(\n",
    "    justice['ImposedSentenceAllChargeInContactEvent'], errors='coerce'\n",
    ")\n",
    "\n",
    "missing_count = justice['imposed_sentence_clean'].isna().sum()\n",
    "total_count = len(justice)\n",
    "missing_prop = missing_count / total_count\n",
    "print(f\"Missing values: {missing_count} ({missing_prop:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be95d13d",
   "metadata": {},
   "source": [
    "Number 4\n",
    "\n",
    "I cleaned the ImposedSentenceAllChargeInContactEvent variable by converting it to numeric and keeping missing values as np.nan. The missing values were not filled because they are informative. They mostly occur for cases with non-custodial sentences or dismissals, as confirmed by examining the SentenceTypeAllChargesAtConvictionInContactEvent variable. This ensures the data accurately represents both recorded sentences and absent sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a60a44e",
   "metadata": {},
   "source": [
    "**Q2.** Go to https://sharkattackfile.net/ and download their dataset on shark attacks (Hint: `GSAF5.xls`).\n",
    "\n",
    "1. Open the shark attack file using Pandas. It is probably not a csv file, so `read_csv` won't work.\n",
    "2. Drop any columns that do not contain data.\n",
    "3. Clean the year variable. Describe the range of values you see. Filter the rows to focus on attacks since 1940. Are attacks increasing, decreasing, or remaining constant over time?\n",
    "4. Clean the Age variable and make a histogram of the ages of the victims.\n",
    "5. What proportion of victims are male?\n",
    "6. Clean the `Type` variable so it only takes three values: Provoked and Unprovoked and Unknown. What proportion of attacks are unprovoked?\n",
    "7. Clean the `Fatal Y/N` variable so it only takes three values: Y, N, and Unknown.\n",
    "8. Are sharks more likely to launch unprovoked attacks on men or women? Is the attack more or less likely to be fatal when the attack is provoked or unprovoked? Is it more or less likely to be fatal when the victim is male or female? How do you feel about sharks?\n",
    "9. What proportion of attacks appear to be by white sharks? (Hint: `str.split()` makes a vector of text values into a list of lists, split by spaces.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f03830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
